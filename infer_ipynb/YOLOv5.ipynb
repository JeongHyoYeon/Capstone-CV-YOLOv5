{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPtudvKJutaEw1xKTt57EL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["images = [\n","    {\n","        \"id\": 14,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/92a4e9d4-ec75-467f-994d-e53041174978\"\n","    },\n","    {\n","        \"id\": 15,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4705f1e1-80da-4d03-86c3-c1b57835b20d\"\n","    },\n","    {\n","        \"id\": 16,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/982ef4c2-dc51-4645-a581-a2525c04d372\"\n","    },\n","    {\n","        \"id\": 17,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5a2c2dcd-8276-4e40-a5f9-a4a946f55364\"\n","    },\n","    {\n","        \"id\": 18,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b37f8797-0599-4566-9af2-967ae6ac22a9\"\n","    },\n","    {\n","        \"id\": 19,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a8e29e45-a740-4fc5-81f2-23f8ede8dd26\"\n","    },\n","    {\n","        \"id\": 20,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/718db959-ffbf-4e45-bd18-40ca476b8a19\"\n","    },\n","    {\n","        \"id\": 21,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/1ad530f9-e6fd-45d8-97f0-c4181df93661\"\n","    },\n","    {\n","        \"id\": 22,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/38076266-ea22-473d-89e0-22d0a189c815\"\n","    },\n","    {\n","        \"id\": 23,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/e16b3f01-0c9b-4451-b7e3-c32ede3af4dc\"\n","    },\n","    {\n","        \"id\": 24,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/44297d97-4ce8-4063-b8ab-ee39dee4397c\"\n","    },\n","    {\n","        \"id\": 25,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0c324854-1e9f-4881-afe4-0ac0cae9cf36\"\n","    },\n","    {\n","        \"id\": 26,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/791484ee-7894-4546-833f-7456f3dbfebc\"\n","    },\n","    {\n","        \"id\": 27,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/91dfaa53-536e-47c6-98f1-64d4180917d3\"\n","    },\n","    {\n","        \"id\": 28,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a2a4db05-0a1e-4965-9809-60314c33bade\"\n","    },\n","    {\n","        \"id\": 29,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3e1f8237-35b4-4182-8bf1-159f744dde03\"\n","    },\n","    {\n","        \"id\": 30,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3bd06b18-1dfd-4211-a2eb-18b8a647135f\"\n","    },\n","    {\n","        \"id\": 31,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2bc23ffa-43d7-40f3-88cd-4ca702fb02be\"\n","    },\n","    {\n","        \"id\": 32,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/7a316a4f-ca6e-4869-bd2f-ff0625be875d\"\n","    },\n","    {\n","        \"id\": 33,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/d6a61ab6-8175-4d9e-87ce-6a2d89e3f53d\"\n","    },\n","    {\n","        \"id\": 34,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/8a7c86e0-cf38-4f7b-a1b4-0a6154c498c9\"\n","    },\n","    {\n","        \"id\": 35,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/32e669c2-79f3-40b9-ab6b-0133385a45a1\"\n","    },\n","    {\n","        \"id\": 36,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/fda7c93c-8811-4796-82d8-7bd76dcfa68c\"\n","    },\n","    {\n","        \"id\": 37,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/57b43dfa-742c-4363-9795-67ca5c01996d\"\n","    },\n","    {\n","        \"id\": 38,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/75e1d1d8-a302-426c-9aa3-36061cd684b6\"\n","    },\n","    {\n","        \"id\": 39,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5b47afef-1d15-4efd-94fa-31b09db51b73\"\n","    },\n","    {\n","        \"id\": 40,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0b6a01eb-4e0b-4470-a9d6-b41320d6b896\"\n","    },\n","    {\n","        \"id\": 41,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4e6ce2d1-a67b-4b20-a284-c56518801b00\"\n","    },\n","    {\n","        \"id\": 42,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3b996ec1-3232-4c7f-9803-b1544ea1fbeb\"\n","    },\n","    {\n","        \"id\": 43,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/466563ef-b390-45ce-858f-62cc12f0ecd5\"\n","    },\n","    {\n","        \"id\": 44,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/650706ac-3b3f-4e31-ac81-294930b87c49\"\n","    },\n","    {\n","        \"id\": 45,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b8524464-79b5-4b8c-8e7b-061e41791add\"\n","    },\n","    {\n","        \"id\": 46,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c26abe17-c776-4c49-84e3-b97bf1b97fc6\"\n","    },\n","    {\n","        \"id\": 47,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/37e8edc7-b4bb-408b-8d2f-8f4c78a3efb0\"\n","    },\n","    {\n","        \"id\": 48,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/bd93c501-ab76-490d-9790-9c61d7a31dde\"\n","    },\n","    {\n","        \"id\": 49,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2ec84e16-f984-40dc-9ead-785c4ecc9ea5\"\n","    },\n","    {\n","        \"id\": 50,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c4b53cae-8583-4fd5-a9f6-838e8a245774\"\n","    },\n","    {\n","        \"id\": 51,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/350b4b83-0fa2-437c-a40a-c4a0acb2584c\"\n","    },\n","    {\n","        \"id\": 52,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b6282776-441b-4094-b738-81f53c0dea51\"\n","    },\n","    {\n","        \"id\": 53,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/efd80ed1-2f33-4a84-aad3-270d75fb3f04\"\n","    },\n","    {\n","        \"id\": 54,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/ce297c12-cc25-432d-b73f-fc8aa5f428ba\"\n","    },\n","    {\n","        \"id\": 55,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/12a9c413-a323-4749-8ffc-a95b10489db0\"\n","    },\n","    {\n","        \"id\": 56,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/96278714-efbe-4624-828b-b9fdda612c21\"\n","    },\n","    {\n","        \"id\": 57,\n","        \"url\": \"https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/21176cba-4fa3-4cd0-bece-61fea1e3cdd2\"\n","    }\n","]"],"metadata":{"id":"O_9z-s_i9LMB","executionInfo":{"status":"ok","timestamp":1683460341803,"user_tz":-540,"elapsed":2,"user":{"displayName":"임연우","userId":"08836425153877533305"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["images.clear()\n","print(len(images))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFy0KbM2BAzk","executionInfo":{"status":"ok","timestamp":1683460340060,"user_tz":-540,"elapsed":403,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"outputId":"082fa754-7db1-4ece-aaed-8611421b6db9"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"akmA9dsz3qRH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683459220527,"user_tz":-540,"elapsed":30658,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"outputId":"9887072d-7192-45bf-ad8c-55630fc9f9c6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# yolov5 clone\n","'''\n","base_path = \"/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/\"\n","%cd {base_path}\n","\n","!git clone https://github.com/ultralytics/yolov5\n","'''"],"metadata":{"id":"sEAnmbKr3_p3","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1683373164233,"user_tz":-540,"elapsed":850,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"outputId":"0ae9a88d-9000-4b04-c2ec-c18eefce042c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nbase_path = \"/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/\"\\n%cd {base_path}\\n\\n!git clone https://github.com/ultralytics/yolov5\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# install\n","base_path = \"/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/\"\n","yolov5_path = base_path + \"yolov5/\"\n","%cd {yolov5_path}\n","%pip install -qr requirements.txt"],"metadata":{"id":"1OGj9xbw3l-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683459231326,"user_tz":-540,"elapsed":9232,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"outputId":"a4684856-71e9-458c-8a8d-3a69e1ef5b9c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/yolov5\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# import\n","\n","#-----(이미지 저장)-----\n","import urllib.request\n","import os\n","import shutil\n","\n","#-----(yolo 기본)-----\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks\n","\n","#-----(yolo Classification, ObjectDetection)-----\n","import argparse\n","import os\n","import platform\n","import sys\n","from pathlib import Path\n","\n","import torch\n","import torch.nn.functional as F\n","\n","ROOT = yolov5_path\n","if str(ROOT) not in sys.path:\n","    sys.path.append(str(ROOT))  # add ROOT to PATH\n","ROOT = Path(ROOT)\n","\n","from models.common import DetectMultiBackend\n","from utils.augmentations import classify_transforms\n","from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\n","from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n","                           increment_path, print_args, strip_optimizer, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n","from utils.plots import Annotator, colors, save_one_box\n","from utils.torch_utils import select_device, smart_inference_mode"],"metadata":{"id":"OfdhHCUP91gl","executionInfo":{"status":"ok","timestamp":1683459262882,"user_tz":-540,"elapsed":28732,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"222cdc95-39fb-4dd8-8d16-6d54095177ea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 v7.0-162-gc3e4e94 Python-3.10.11 torch-2.0.0+cu118 CPU\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.4/107.7 GB disk)\n"]}]},{"cell_type":"code","source":["def download_images(images, images_folder_path, re_download):\n","  # 폴더 생성\n","  if os.path.exists(images_folder_path):\n","    if re_download:\n","      shutil.rmtree(images_folder_path)\n","      os.mkdir(images_folder_path)\n","  else :\n","    os.mkdir(images_folder_path)\n","\n","  # 이미지 저장\n","  if re_download:\n","    for idx, image in enumerate(images):\n","      urllib.request.urlretrieve(image[\"url\"], images_folder_path + str(image[\"id\"]) + \".jpg\")"],"metadata":{"id":"EwA2WhATXUWd","executionInfo":{"status":"ok","timestamp":1683460019355,"user_tz":-540,"elapsed":4,"user":{"displayName":"임연우","userId":"08836425153877533305"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n","\n","def run_yolov5_scene(\n","        images,\n","        base_path,\n","        yolov5_path,\n","        classification_threshold=0.4, #probability threshold\n","\n","        weights=ROOT / 'yolov5s-cls.pt',  # model.pt path(s)\n","        source=ROOT / 'data/images',  # file/dir/URL/glob/screen/0(webcam)\n","        nosave=False,  # do not save images/videos\n","\n","        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path\n","        imgsz=(224, 224),  # inference size (height, width)\n","        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n","        view_img=False,  # show results\n","        save_txt=False,  # save results to *.txt\n","        augment=False,  # augmented inference\n","        visualize=False,  # visualize features\n","        update=False,  # update all models\n","        project=ROOT / 'runs/predict-cls',  # save results to project/name\n","        name='exp',  # save results to project/name\n","        exist_ok=False,  # existing project/name ok, do not increment\n","        half=False,  # use FP16 half-precision inference\n","        dnn=False,  # use OpenCV DNN for ONNX inference\n","        vid_stride=1,  # video frame-rate stride\n","):\n","    \"\"\"\n","    yolov5 classification을 run시켜서 images에 scene tag를 추가하는 함수로\n","    Ultralytics의 yolov5/classify/predict.py를 변형한 함수.\n","\n","    Args:\n","      images (list) : [{\n","                      \"id\" : DB에서 이미지 id\n","                      \"url\" : S3에서 생성한 url\n","                    }]\n","      \n","    Returns:\n","      images (list) : [{\n","                      \"id\" : DB에서 이미지 id\n","                      \"url\" : S3에서 생성한 url\n","                      \"yolo_tag\" :  (1) pretrained yolov5로 scene classification [scene tag] \n","                      \"yolo_scene_prob\" : scene classification했을 때의 probability\n","                    }]\n","    \"\"\"\n","    #check\n","    check_requirements(exclude=('tensorboard', 'thop'))\n","\n","    source = str(source)\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n","    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n","    webcam = source.isnumeric() or source.endswith('.streams') or (is_url and not is_file)\n","    screenshot = source.lower().startswith('screen')\n","    if is_url and is_file:\n","        source = check_file(source)  # download\n","\n","    # Directories\n","    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n","    if not nosave:\n","      (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Load model\n","    device = select_device(device)\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","    stride, names, pt = model.stride, model.names, model.pt\n","    imgsz = check_img_size(imgsz, s=stride)  # check image size\n","\n","    # Dataloader\n","    bs = 1  # batch_size\n","    if webcam:\n","        view_img = check_imshow(warn=True)\n","        dataset = LoadStreams(source, img_size=imgsz, transforms=classify_transforms(imgsz[0]), vid_stride=vid_stride)\n","        bs = len(dataset)\n","    elif screenshot:\n","        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, transforms=classify_transforms(imgsz[0]), vid_stride=vid_stride)\n","    vid_path, vid_writer = [None] * bs, [None] * bs\n","\n","    # Run inference\n","    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n","    seen, windows, dt = 0, [], (Profile(), Profile(), Profile())\n","    \n","    images_idx = 0 # (YeonWoo)\n","\n","    for path, im, im0s, vid_cap, s in dataset:\n","        with dt[0]:\n","            im = torch.Tensor(im).to(model.device)\n","            im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n","            if len(im.shape) == 3:\n","                im = im[None]  # expand for batch dim\n","\n","        # Inference\n","        with dt[1]:\n","            results = model(im)\n","\n","        # Post-process\n","        with dt[2]:\n","            pred = F.softmax(results, dim=1)  # probabilities\n","\n","        # Process predictions\n","        for i, prob in enumerate(pred):  # per image\n","            seen += 1\n","            if webcam:  # batch_size >= 1\n","                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n","                s += f'{i}: '\n","            else:\n","                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n","\n","            p = Path(p)  # to Path\n","            save_path = str(save_dir / p.name)  # im.jpg\n","            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n","\n","            s += '%gx%g ' % im.shape[2:]  # print string\n","            annotator = Annotator(im0, example=str(names), pil=True)\n","\n","            # Print results\n","            top5i = prob.argsort(0, descending=True)[:5].tolist()  # top 5 indices\n","            s += f\"{', '.join(f'{names[j]} {prob[j]:.2f}' for j in top5i)}, \"\n","\n","            # (YeonWoo) tag_temp, prob_temp 구하기\n","            tag_temp = []\n","            prob_temp = []\n","\n","            for j in top5i:\n","                if(prob[j] >= classification_threshold):\n","                    tag_temp.append(names[j])\n","                    prob_temp.append(round(float(prob[j]), 3)) # tensor -> float -> 반올림\n","\n","            # (YeonWoo) images에 tag & prob 추가\n","            #(images id 구하는 코드. 필요없었음. images idx만 구하면됨.)\n","            #file_name = os.path.split(path)[1] # 전체 경로에서 file name만 parsing\n","            #images_idx = int(file_name.split('.')[0]) # 45.jpg에서 \"45\" parsing -> int로 변경경\n","            images[images_idx][\"yolo_tag\"] = tag_temp\n","            images[images_idx][\"yolo_detail\"] = prob_temp\n","            images_idx = images_idx+1\n","\n","            '''\n","            # Write results\n","            text = '\\n'.join(f'{prob[j]:.2f} {names[j]}' for j in top5i)\n","            if save_img or view_img:  # Add bbox to image\n","                annotator.text((32, 32), text, txt_color=(255, 255, 255))\n","            if save_txt:  # Write to file\n","                with open(f'{txt_path}.txt', 'a') as f:\n","                    f.write(text + '\\n')\n","\n","            # Stream results\n","            im0 = annotator.result()\n","            if view_img:\n","                if platform.system() == 'Linux' and p not in windows:\n","                    windows.append(p)\n","                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)\n","                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])\n","                cv2.imshow(str(p), im0)\n","                cv2.waitKey(1)  # 1 millisecond\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'image':\n","                    cv2.imwrite(save_path, im0)\n","                else:  # 'video' or 'stream'\n","                    if vid_path[i] != save_path:  # new video\n","                        vid_path[i] = save_path\n","                        if isinstance(vid_writer[i], cv2.VideoWriter):\n","                            vid_writer[i].release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n","                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer[i].write(im0)\n","              '''\n","\n","        # Print time (inference-only)\n","        LOGGER.info(f'{s}{dt[1].dt * 1E3:.1f}ms')\n","\n","    # Print results\n","    t = tuple(x.t / seen * 1E3 for x in dt)  # speeds per image\n","    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n","    if save_txt or save_img:\n","        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n","        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n","    if update:\n","        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)\n","\n","    return images"],"metadata":{"id":"gA2toMyB_1k4","executionInfo":{"status":"ok","timestamp":1683460346503,"user_tz":-540,"elapsed":424,"user":{"displayName":"임연우","userId":"08836425153877533305"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n","\n","def run_yolov5_object(\n","        images,\n","        base_path,\n","        yolov5_path,\n","\n","        weights=ROOT / 'yolov5s-cls.pt',  # model.pt path(s)\n","        source=ROOT / 'data/images',  # file/dir/URL/glob/screen/0(webcam)\n","        nosave=False,  # do not save images/videos\n","\n","        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path\n","        imgsz=(640, 640),  # inference size (height, width)\n","        conf_thres=0.25,  # confidence threshold\n","        iou_thres=0.45,  # NMS IOU threshold\n","        max_det=1000,  # maximum detections per image\n","        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n","        view_img=False,  # show results\n","        save_txt=False,  # save results to *.txt\n","        save_conf=False,  # save confidences in --save-txt labels\n","        save_crop=False,  # save cropped prediction boxes\n","        classes=None,  # filter by class: --class 0, or --class 0 2 3\n","        agnostic_nms=False,  # class-agnostic NMS\n","        augment=False,  # augmented inference\n","        visualize=False,  # visualize features\n","        update=False,  # update all models\n","        project=ROOT / 'runs/detect',  # save results to project/name\n","        name='exp',  # save results to project/name\n","        exist_ok=False,  # existing project/name ok, do not increment\n","        line_thickness=3,  # bounding box thickness (pixels)\n","        hide_labels=False,  # hide labels\n","        hide_conf=False,  # hide confidences\n","        half=False,  # use FP16 half-precision inference\n","        dnn=False,  # use OpenCV DNN for ONNX inference\n","        vid_stride=1,  # video frame-rate stride\n","): \n","    \"\"\"\n","    yolov5 object detection을 run시켜서 images에 object tag를 추가하는 함수로\n","    Ultralytics의 yolov5/detect.py를 변형한 함수.\n","\n","    Args:\n","      images (list) : [{\n","                      \"id\" : DB에서 이미지 id\n","                      \"url\" : S3에서 생성한 url\n","                      \"yolo_tag\" :  (1) pretrained yolov5로 scene classification [scene tag] \n","                      \"yolo_detail\" : scene classification했을 때의 probability\n","                    }]\n","      \n","    Returns:\n","      images (list) : [{\n","                      \"id\" (int) : DB에서 이미지 id\n","                      \"url\" (str) : S3에서 생성한 url\n","                      \"yolo_tag\" (str list) : (1) pretrained yolov5로 scene classification [scene tag] \n","                                              (2) pretrained yolov5로 obejct detectoin [object tag]\n","                      \"yolo_detail\" (list) :  (1)의 경우, scene classification했을때 해당 tag에 대한 probability\n","                                              (2)의 경우, object detection 했을때 해당 tag가 몇번 등장했는지\n","                    }]\n","    \"\"\"\n","    source = str(source)\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n","    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n","    webcam = source.isnumeric() or source.endswith('.streams') or (is_url and not is_file)\n","    screenshot = source.lower().startswith('screen')\n","    if is_url and is_file:\n","        source = check_file(source)  # download\n","\n","    # Directories\n","    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n","    if not nosave:\n","      (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Load model\n","    device = select_device(device)\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","    stride, names, pt = model.stride, model.names, model.pt\n","    imgsz = check_img_size(imgsz, s=stride)  # check image size\n","\n","    # Dataloader\n","    bs = 1  # batch_size\n","    if webcam:\n","        view_img = check_imshow(warn=True)\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n","        bs = len(dataset)\n","    elif screenshot:\n","        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n","    vid_path, vid_writer = [None] * bs, [None] * bs\n","\n","    # Run inference\n","    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup\n","    seen, windows, dt = 0, [], (Profile(), Profile(), Profile())\n","\n","    images_idx = -1 # (YeonWoo)\n","\n","    for path, im, im0s, vid_cap, s in dataset:\n","        with dt[0]:\n","            im = torch.from_numpy(im).to(model.device)\n","            im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n","            im /= 255  # 0 - 255 to 0.0 - 1.0\n","            if len(im.shape) == 3:\n","                im = im[None]  # expand for batch dim\n","\n","        # Inference\n","        with dt[1]:\n","            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n","            pred = model(im, augment=augment, visualize=visualize)\n","\n","        # NMS\n","        with dt[2]:\n","            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n","\n","        # Second-stage classifier (optional)\n","        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)\n","\n","        # Process predictions\n","        for i, det in enumerate(pred):  # per image\n","            seen += 1\n","            if webcam:  # batch_size >= 1\n","                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n","                s += f'{i}: '\n","            else:\n","                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n","\n","            p = Path(p)  # to Path\n","            save_path = str(save_dir / p.name)  # im.jpg\n","            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n","            s += '%gx%g ' % im.shape[2:]  # print string\n","            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","            imc = im0.copy() if save_crop else im0  # for save_crop\n","            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n","\n","            images_idx = images_idx+1\n","\n","            if len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results \n","                for c in det[:, 5].unique():\n","                    n = (det[:, 5] == c).sum()  # detections per class\n","                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","\n","                    # (YeonWoo) images에 tag, num 추가\n","                    # 이미 run_yolov5_scene 함수가 호출되었으므로 기존 list에 append.\n","                    images[images_idx][\"yolo_tag\"].append(names[int(c)])\n","                    images[images_idx][\"yolo_detail\"].append(int(n)) #해당 class의 num\n","\n","                # Write results\n","                for *xyxy, conf, cls in reversed(det):\n","                    if save_txt:  # Write to file\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n","                        with open(f'{txt_path}.txt', 'a') as f:\n","                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n","\n","                    if save_img or save_crop or view_img:  # Add bbox to image\n","                        c = int(cls)  # integer class\n","                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n","                        annotator.box_label(xyxy, label, color=colors(c, True))\n","                    if save_crop:\n","                        save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n","\n","            # Stream results\n","            im0 = annotator.result()\n","            if view_img:\n","                if platform.system() == 'Linux' and p not in windows:\n","                    windows.append(p)\n","                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)\n","                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])\n","                cv2.imshow(str(p), im0)\n","                cv2.waitKey(1)  # 1 millisecond\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'image':\n","                    cv2.imwrite(save_path, im0)\n","                else:  # 'video' or 'stream'\n","                    if vid_path[i] != save_path:  # new video\n","                        vid_path[i] = save_path\n","                        if isinstance(vid_writer[i], cv2.VideoWriter):\n","                            vid_writer[i].release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n","                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer[i].write(im0)\n","\n","        # Print time (inference-only)\n","        LOGGER.info(f\"{s}{'' if len(det) else '(no detections), '}{dt[1].dt * 1E3:.1f}ms\")\n","\n","    # Print results\n","    t = tuple(x.t / seen * 1E3 for x in dt)  # speeds per image\n","    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n","    if save_txt or save_img:\n","        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n","        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n","    if update:\n","        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)\n","\n","    return images"],"metadata":{"id":"sBMNdPFhAII7","executionInfo":{"status":"ok","timestamp":1683460350396,"user_tz":-540,"elapsed":594,"user":{"displayName":"임연우","userId":"08836425153877533305"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#----------------------------------------------------------\n","#                        main \n","#----------------------------------------------------------\n","def run_yolov5(images):\n","  \"\"\"\n","    pretrained yolov5 모델로\n","    (1) scene classification 수행해 [scene tag]를\n","    (2) obejct detectoin 수행해 [object tag]를\n","    infer하는 함수.\n","\n","    Args:\n","      images (list) : [{\n","                      \"id\" (int) : DB에서 이미지 id\n","                      \"url\" (str) : S3에서 생성한 url\n","                    }]\n","      \n","    Returns:\n","      images (list) : [{\n","                      \"id\" (int) : DB에서 이미지 id\n","                      \"url\" (str) : S3에서 생성한 url\n","                      \"yolo_tag\" (str list) : (1) pretrained yolov5로 scene classification [scene tag] \n","                                              (2) pretrained yolov5로 obejct detectoin [object tag]\n","                      \"yolo_detail\" (list) :  (1)의 경우, scene classification했을때 해당 tag에 대한 probability\n","                                              (2)의 경우, object detection 했을때 해당 tag가 몇번 등장했는지\n","                    }]\n","  \"\"\"\n","  print(\"==========START YOLOV5==========\\n\")\n","\n","  re_download = False\n","\n","  base_path = \"/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/\"\n","  yolov5_path = base_path + \"yolov5/\"\n","  images_folder_path = base_path + \"images/\"\n","\n","  %cd {base_path}\n","  # [STEP 0. url로 이미지 다운받아 images 폴더에 저장]\n","  print(\"\\n\\n\")\n","  print(\"Step0. download images at folder\\n\")\n","  download_images(images, images_folder_path, re_download)\n","\n","  \n","  %cd {yolov5_path}\n","  # [STEP 1. yolov5 : scene classification [scene tag] ]\n","  print(\"\\n\\n\")\n","  print(\"Step1. scene classification\\n\")\n","  #!python ./yolov5/classify/predict.py --weights checkpoint/yolov5_scene_best.pt --source \"images/*.jpg\" --nosave #!python [classify/predict.py경로] [--weights weight경로] [--source test_input_경로]\n","  images = run_yolov5_scene(\n","    images,\n","    base_path,\n","    yolov5_path,\n","    classification_threshold= 0.4,\n","    weights= \"../checkpoint/yolov5_scene_best.pt\",  # model.pt path(s)\n","    source= \"../images/*.jpg\",  # file/dir/URL/glob/screen/0(webcam)\n","    nosave= True,  # do not save images/videos\n","  )\n","\n","  for i, img in enumerate(images):\n","    print(\"idx = \", i)\n","    print(img)\n","    print(\" \")\n","\n","  # [STEP 2. yolov5 : object detection [object tag] ]\n","  print(\"\\n\\n\")\n","  print(\"Step2. object detection\\n\")\n","  #!python ./yolov5/detect.py --weights checkpoint/yolov5_object_best.pt --source \"images/*.jpg\" #--img 416 --conf 0.4 #!python [detect.py경로] [--weights weight경로] [--source test_input_경로] [-img 추론이미지사이즈] [--conf 신뢰도 threshold]\n","  images = run_yolov5_object(\n","    images,\n","    base_path,\n","    yolov5_path,\n","    weights= \"../checkpoint/yolov5_object_best.pt\",  # model.pt path(s)\n","    source= \"../images/*.jpg\",  # file/dir/URL/glob/screen/0(webcam)\n","    nosave= True,  # do not save images/videos\n","  )\n","\n","  for i, img in enumerate(images):\n","    print(\"idx = \", i)\n","    print(img)\n","    print(\" \")\n","  return images\n","  print(\"==========END YOLOV5==========\\n\")"],"metadata":{"id":"x76DCt4Q9-9I","executionInfo":{"status":"ok","timestamp":1683460356615,"user_tz":-540,"elapsed":425,"user":{"displayName":"임연우","userId":"08836425153877533305"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["images = run_yolov5(images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THQRqW8OesS9","executionInfo":{"status":"ok","timestamp":1683460382671,"user_tz":-540,"elapsed":20283,"user":{"displayName":"임연우","userId":"08836425153877533305"}},"outputId":"6fb410dd-e645-46d3-8413-10ee943ea9d1"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 v7.0-162-gc3e4e94 Python-3.10.11 torch-2.0.0+cu118 CPU\n","\n","Fusing layers... \n"]},{"output_type":"stream","name":"stdout","text":["==========START YOLOV5==========\n","\n","/content/drive/MyDrive/Capstone_Yolov5/3_Yolo\n","\n","\n","\n","Step0. download images at folder\n","\n","/content/drive/MyDrive/Capstone_Yolov5/3_Yolo/yolov5\n","\n","\n","\n","Step1. scene classification\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/requirements.txt not found, check failed.\n"]},{"output_type":"stream","name":"stderr","text":["Model summary: 117 layers, 4176936 parameters, 0 gradients, 10.4 GFLOPs\n","image 1/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/14.jpg: 224x224 coast 0.69, Opencountry 0.10, mountain 0.09, highway 0.04, street 0.02, 54.0ms\n","image 2/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/15.jpg: 224x224 coast 0.65, Opencountry 0.22, mountain 0.05, forest 0.02, tallbuilding 0.02, 56.4ms\n","image 3/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/16.jpg: 224x224 coast 0.83, inside_city 0.05, highway 0.05, street 0.03, forest 0.02, 52.6ms\n","image 4/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/17.jpg: 224x224 coast 0.62, highway 0.18, mountain 0.05, Opencountry 0.05, street 0.05, 53.9ms\n","image 5/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/18.jpg: 224x224 coast 0.64, inside_city 0.14, street 0.06, mountain 0.04, forest 0.04, 53.0ms\n","image 6/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/19.jpg: 224x224 inside_city 0.61, mountain 0.15, coast 0.13, street 0.05, Opencountry 0.02, 54.4ms\n","image 7/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/20.jpg: 224x224 coast 0.38, inside_city 0.21, street 0.11, Opencountry 0.08, tallbuilding 0.06, 56.1ms\n","image 8/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/21.jpg: 224x224 highway 0.38, coast 0.29, tallbuilding 0.11, Opencountry 0.07, forest 0.04, 53.0ms\n","image 9/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/22.jpg: 224x224 street 0.48, highway 0.11, tallbuilding 0.10, inside_city 0.09, mountain 0.08, 57.5ms\n","image 10/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/23.jpg: 224x224 Opencountry 0.70, street 0.12, mountain 0.06, highway 0.06, inside_city 0.02, 54.5ms\n","image 11/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/24.jpg: 224x224 inside_city 0.50, street 0.22, Opencountry 0.09, mountain 0.06, forest 0.05, 52.2ms\n","image 12/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/25.jpg: 224x224 street 0.35, tallbuilding 0.19, mountain 0.17, inside_city 0.11, highway 0.09, 59.5ms\n","image 13/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/26.jpg: 224x224 forest 0.22, mountain 0.22, street 0.14, tallbuilding 0.13, inside_city 0.12, 55.0ms\n","image 14/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/27.jpg: 224x224 highway 0.33, inside_city 0.19, street 0.17, tallbuilding 0.10, forest 0.08, 54.4ms\n","image 15/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/28.jpg: 224x224 street 0.49, inside_city 0.17, tallbuilding 0.09, Opencountry 0.09, mountain 0.06, 54.9ms\n","image 16/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/29.jpg: 224x224 street 0.31, tallbuilding 0.25, forest 0.19, coast 0.06, highway 0.06, 61.6ms\n","image 17/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/30.jpg: 224x224 Opencountry 0.64, street 0.11, highway 0.08, forest 0.06, inside_city 0.04, 54.1ms\n","image 18/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/31.jpg: 224x224 street 0.56, inside_city 0.19, coast 0.09, tallbuilding 0.05, Opencountry 0.03, 51.8ms\n","image 19/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/32.jpg: 224x224 street 0.75, Opencountry 0.06, mountain 0.06, forest 0.04, highway 0.03, 59.3ms\n","image 20/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/33.jpg: 224x224 forest 0.86, Opencountry 0.04, mountain 0.03, coast 0.02, highway 0.02, 56.0ms\n","image 21/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/34.jpg: 224x224 forest 0.41, street 0.26, tallbuilding 0.13, coast 0.05, highway 0.05, 53.5ms\n","image 22/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/35.jpg: 224x224 tallbuilding 0.48, street 0.18, coast 0.09, inside_city 0.06, Opencountry 0.06, 57.6ms\n","image 23/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/36.jpg: 224x224 tallbuilding 0.48, mountain 0.28, highway 0.06, Opencountry 0.06, forest 0.04, 57.7ms\n","image 24/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/37.jpg: 224x224 highway 0.53, mountain 0.20, street 0.12, inside_city 0.08, tallbuilding 0.04, 54.8ms\n","image 25/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/38.jpg: 224x224 mountain 0.85, Opencountry 0.06, street 0.03, inside_city 0.03, tallbuilding 0.01, 53.9ms\n","image 26/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/39.jpg: 224x224 inside_city 0.31, street 0.28, tallbuilding 0.12, highway 0.07, forest 0.06, 53.9ms\n","image 27/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/40.jpg: 224x224 street 0.27, mountain 0.20, tallbuilding 0.14, Opencountry 0.14, forest 0.13, 53.6ms\n","image 28/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/41.jpg: 224x224 mountain 0.48, Opencountry 0.14, forest 0.13, coast 0.07, highway 0.06, 53.8ms\n","image 29/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/42.jpg: 224x224 forest 0.26, mountain 0.24, coast 0.17, Opencountry 0.13, tallbuilding 0.09, 53.6ms\n","image 30/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/43.jpg: 224x224 coast 0.89, mountain 0.03, tallbuilding 0.02, forest 0.02, street 0.02, 55.1ms\n","image 31/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/44.jpg: 224x224 coast 0.91, inside_city 0.02, forest 0.02, tallbuilding 0.01, street 0.01, 56.1ms\n","image 32/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/45.jpg: 224x224 mountain 0.37, street 0.23, highway 0.11, tallbuilding 0.11, inside_city 0.07, 54.8ms\n","image 33/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/46.jpg: 224x224 mountain 0.61, street 0.08, highway 0.07, inside_city 0.07, tallbuilding 0.06, 54.0ms\n","image 34/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/47.jpg: 224x224 mountain 0.43, inside_city 0.31, tallbuilding 0.09, street 0.06, highway 0.04, 57.7ms\n","image 35/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/48.jpg: 224x224 inside_city 0.54, mountain 0.17, street 0.13, Opencountry 0.05, highway 0.04, 55.2ms\n","image 36/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/49.jpg: 224x224 street 0.22, mountain 0.19, inside_city 0.17, coast 0.12, tallbuilding 0.10, 53.7ms\n","image 37/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/50.jpg: 224x224 inside_city 0.32, highway 0.30, mountain 0.10, street 0.09, tallbuilding 0.06, 54.1ms\n","image 38/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/51.jpg: 224x224 mountain 0.76, highway 0.06, street 0.05, tallbuilding 0.05, inside_city 0.05, 50.5ms\n","image 39/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/52.jpg: 224x224 highway 0.45, Opencountry 0.19, street 0.15, tallbuilding 0.06, coast 0.06, 53.1ms\n","image 40/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/53.jpg: 224x224 mountain 0.71, Opencountry 0.07, street 0.07, inside_city 0.06, tallbuilding 0.03, 52.1ms\n","image 41/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/54.jpg: 224x224 mountain 0.47, inside_city 0.44, Opencountry 0.04, street 0.01, coast 0.01, 51.0ms\n","image 42/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/55.jpg: 224x224 mountain 0.40, inside_city 0.39, highway 0.06, Opencountry 0.04, tallbuilding 0.04, 53.4ms\n","image 43/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/56.jpg: 224x224 inside_city 0.46, street 0.26, mountain 0.08, tallbuilding 0.07, coast 0.05, 53.5ms\n","image 44/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/57.jpg: 224x224 inside_city 0.33, mountain 0.27, street 0.12, coast 0.08, Opencountry 0.08, 54.2ms\n","Speed: 0.0ms pre-process, 54.7ms inference, 0.0ms NMS per image at shape (1, 3, 224, 224)\n","YOLOv5 🚀 v7.0-162-gc3e4e94 Python-3.10.11 torch-2.0.0+cu118 CPU\n","\n"]},{"output_type":"stream","name":"stdout","text":["idx =  0\n","{'id': 14, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/92a4e9d4-ec75-467f-994d-e53041174978', 'yolo_tag': ['coast'], 'yolo_detail': [0.691]}\n"," \n","idx =  1\n","{'id': 15, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4705f1e1-80da-4d03-86c3-c1b57835b20d', 'yolo_tag': ['coast'], 'yolo_detail': [0.653]}\n"," \n","idx =  2\n","{'id': 16, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/982ef4c2-dc51-4645-a581-a2525c04d372', 'yolo_tag': ['coast'], 'yolo_detail': [0.828]}\n"," \n","idx =  3\n","{'id': 17, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5a2c2dcd-8276-4e40-a5f9-a4a946f55364', 'yolo_tag': ['coast'], 'yolo_detail': [0.616]}\n"," \n","idx =  4\n","{'id': 18, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b37f8797-0599-4566-9af2-967ae6ac22a9', 'yolo_tag': ['coast'], 'yolo_detail': [0.641]}\n"," \n","idx =  5\n","{'id': 19, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a8e29e45-a740-4fc5-81f2-23f8ede8dd26', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.606]}\n"," \n","idx =  6\n","{'id': 20, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/718db959-ffbf-4e45-bd18-40ca476b8a19', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  7\n","{'id': 21, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/1ad530f9-e6fd-45d8-97f0-c4181df93661', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  8\n","{'id': 22, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/38076266-ea22-473d-89e0-22d0a189c815', 'yolo_tag': ['street'], 'yolo_detail': [0.482]}\n"," \n","idx =  9\n","{'id': 23, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/e16b3f01-0c9b-4451-b7e3-c32ede3af4dc', 'yolo_tag': ['Opencountry'], 'yolo_detail': [0.699]}\n"," \n","idx =  10\n","{'id': 24, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/44297d97-4ce8-4063-b8ab-ee39dee4397c', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.495]}\n"," \n","idx =  11\n","{'id': 25, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0c324854-1e9f-4881-afe4-0ac0cae9cf36', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  12\n","{'id': 26, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/791484ee-7894-4546-833f-7456f3dbfebc', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  13\n","{'id': 27, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/91dfaa53-536e-47c6-98f1-64d4180917d3', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  14\n","{'id': 28, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a2a4db05-0a1e-4965-9809-60314c33bade', 'yolo_tag': ['street'], 'yolo_detail': [0.492]}\n"," \n","idx =  15\n","{'id': 29, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3e1f8237-35b4-4182-8bf1-159f744dde03', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  16\n","{'id': 30, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3bd06b18-1dfd-4211-a2eb-18b8a647135f', 'yolo_tag': ['Opencountry'], 'yolo_detail': [0.639]}\n"," \n","idx =  17\n","{'id': 31, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2bc23ffa-43d7-40f3-88cd-4ca702fb02be', 'yolo_tag': ['street'], 'yolo_detail': [0.562]}\n"," \n","idx =  18\n","{'id': 32, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/7a316a4f-ca6e-4869-bd2f-ff0625be875d', 'yolo_tag': ['street'], 'yolo_detail': [0.75]}\n"," \n","idx =  19\n","{'id': 33, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/d6a61ab6-8175-4d9e-87ce-6a2d89e3f53d', 'yolo_tag': ['forest'], 'yolo_detail': [0.86]}\n"," \n","idx =  20\n","{'id': 34, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/8a7c86e0-cf38-4f7b-a1b4-0a6154c498c9', 'yolo_tag': ['forest'], 'yolo_detail': [0.407]}\n"," \n","idx =  21\n","{'id': 35, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/32e669c2-79f3-40b9-ab6b-0133385a45a1', 'yolo_tag': ['tallbuilding'], 'yolo_detail': [0.482]}\n"," \n","idx =  22\n","{'id': 36, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/fda7c93c-8811-4796-82d8-7bd76dcfa68c', 'yolo_tag': ['tallbuilding'], 'yolo_detail': [0.481]}\n"," \n","idx =  23\n","{'id': 37, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/57b43dfa-742c-4363-9795-67ca5c01996d', 'yolo_tag': ['highway'], 'yolo_detail': [0.532]}\n"," \n","idx =  24\n","{'id': 38, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/75e1d1d8-a302-426c-9aa3-36061cd684b6', 'yolo_tag': ['mountain'], 'yolo_detail': [0.849]}\n"," \n","idx =  25\n","{'id': 39, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5b47afef-1d15-4efd-94fa-31b09db51b73', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  26\n","{'id': 40, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0b6a01eb-4e0b-4470-a9d6-b41320d6b896', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  27\n","{'id': 41, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4e6ce2d1-a67b-4b20-a284-c56518801b00', 'yolo_tag': ['mountain'], 'yolo_detail': [0.481]}\n"," \n","idx =  28\n","{'id': 42, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3b996ec1-3232-4c7f-9803-b1544ea1fbeb', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  29\n","{'id': 43, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/466563ef-b390-45ce-858f-62cc12f0ecd5', 'yolo_tag': ['coast'], 'yolo_detail': [0.887]}\n"," \n","idx =  30\n","{'id': 44, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/650706ac-3b3f-4e31-ac81-294930b87c49', 'yolo_tag': ['coast'], 'yolo_detail': [0.911]}\n"," \n","idx =  31\n","{'id': 45, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b8524464-79b5-4b8c-8e7b-061e41791add', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  32\n","{'id': 46, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c26abe17-c776-4c49-84e3-b97bf1b97fc6', 'yolo_tag': ['mountain'], 'yolo_detail': [0.606]}\n"," \n","idx =  33\n","{'id': 47, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/37e8edc7-b4bb-408b-8d2f-8f4c78a3efb0', 'yolo_tag': ['mountain'], 'yolo_detail': [0.428]}\n"," \n","idx =  34\n","{'id': 48, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/bd93c501-ab76-490d-9790-9c61d7a31dde', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.536]}\n"," \n","idx =  35\n","{'id': 49, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2ec84e16-f984-40dc-9ead-785c4ecc9ea5', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  36\n","{'id': 50, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c4b53cae-8583-4fd5-a9f6-838e8a245774', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  37\n","{'id': 51, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/350b4b83-0fa2-437c-a40a-c4a0acb2584c', 'yolo_tag': ['mountain'], 'yolo_detail': [0.76]}\n"," \n","idx =  38\n","{'id': 52, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b6282776-441b-4094-b738-81f53c0dea51', 'yolo_tag': ['highway'], 'yolo_detail': [0.45]}\n"," \n","idx =  39\n","{'id': 53, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/efd80ed1-2f33-4a84-aad3-270d75fb3f04', 'yolo_tag': ['mountain'], 'yolo_detail': [0.71]}\n"," \n","idx =  40\n","{'id': 54, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/ce297c12-cc25-432d-b73f-fc8aa5f428ba', 'yolo_tag': ['mountain', 'inside_city'], 'yolo_detail': [0.472, 0.441]}\n"," \n","idx =  41\n","{'id': 55, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/12a9c413-a323-4749-8ffc-a95b10489db0', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  42\n","{'id': 56, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/96278714-efbe-4624-828b-b9fdda612c21', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.46]}\n"," \n","idx =  43\n","{'id': 57, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/21176cba-4fa3-4cd0-bece-61fea1e3cdd2', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","\n","\n","\n","Step2. object detection\n","\n"]},{"output_type":"stream","name":"stderr","text":["Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 7459581 parameters, 0 gradients\n","image 1/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/14.jpg: 544x640 (no detections), 362.9ms\n","image 2/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/15.jpg: 480x640 (no detections), 317.8ms\n","image 3/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/16.jpg: 448x640 (no detections), 293.9ms\n","image 4/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/17.jpg: 480x640 (no detections), 311.0ms\n","image 5/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/18.jpg: 480x640 1 person, 316.5ms\n","image 6/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/19.jpg: 416x640 (no detections), 280.0ms\n","image 7/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/20.jpg: 448x640 (no detections), 293.9ms\n","image 8/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/21.jpg: 448x640 1 person, 293.9ms\n","image 9/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/22.jpg: 448x640 (no detections), 303.6ms\n","image 10/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/23.jpg: 448x640 (no detections), 300.5ms\n","image 11/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/24.jpg: 448x640 (no detections), 288.9ms\n","image 12/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/25.jpg: 448x640 (no detections), 305.0ms\n","image 13/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/26.jpg: 480x640 (no detections), 324.8ms\n","image 14/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/27.jpg: 480x640 5 persons, 316.6ms\n","image 15/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/28.jpg: 448x640 2 persons, 292.7ms\n","image 16/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/29.jpg: 416x640 1 person, 277.1ms\n","image 17/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/30.jpg: 448x640 (no detections), 291.4ms\n","image 18/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/31.jpg: 448x640 (no detections), 308.7ms\n","image 19/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/32.jpg: 448x640 2 persons, 451.3ms\n","image 20/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/33.jpg: 320x640 (no detections), 208.6ms\n","image 21/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/34.jpg: 448x640 (no detections), 429.1ms\n","image 22/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/35.jpg: 448x640 (no detections), 317.7ms\n","image 23/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/36.jpg: 480x640 (no detections), 309.4ms\n","image 24/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/37.jpg: 480x640 (no detections), 323.9ms\n","image 25/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/38.jpg: 640x544 (no detections), 368.1ms\n","image 26/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/39.jpg: 384x640 (no detections), 253.2ms\n","image 27/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/40.jpg: 448x640 (no detections), 304.3ms\n","image 28/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/41.jpg: 448x640 (no detections), 302.9ms\n","image 29/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/42.jpg: 448x640 (no detections), 296.2ms\n","image 30/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/43.jpg: 448x640 (no detections), 308.0ms\n","image 31/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/44.jpg: 480x640 (no detections), 439.2ms\n","image 32/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/45.jpg: 640x448 (no detections), 485.2ms\n","image 33/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/46.jpg: 480x640 (no detections), 530.2ms\n","image 34/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/47.jpg: 448x640 (no detections), 472.4ms\n","image 35/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/48.jpg: 448x640 (no detections), 486.8ms\n","image 36/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/49.jpg: 544x640 (no detections), 576.9ms\n","image 37/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/50.jpg: 640x640 (no detections), 696.0ms\n","image 38/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/51.jpg: 640x544 (no detections), 601.9ms\n","image 39/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/52.jpg: 640x320 1 person, 286.8ms\n","image 40/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/53.jpg: 448x640 (no detections), 294.5ms\n","image 41/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/54.jpg: 384x640 4 bowls, 258.5ms\n","image 42/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/55.jpg: 416x640 5 bowls, 273.6ms\n","image 43/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/56.jpg: 640x544 (no detections), 597.4ms\n","image 44/44 /content/drive/MyDrive/Capstone_Yolov5/3_Yolo/images/57.jpg: 384x640 (no detections), 334.9ms\n","Speed: 0.9ms pre-process, 356.5ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stdout","text":["idx =  0\n","{'id': 14, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/92a4e9d4-ec75-467f-994d-e53041174978', 'yolo_tag': ['coast'], 'yolo_detail': [0.691]}\n"," \n","idx =  1\n","{'id': 15, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4705f1e1-80da-4d03-86c3-c1b57835b20d', 'yolo_tag': ['coast'], 'yolo_detail': [0.653]}\n"," \n","idx =  2\n","{'id': 16, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/982ef4c2-dc51-4645-a581-a2525c04d372', 'yolo_tag': ['coast'], 'yolo_detail': [0.828]}\n"," \n","idx =  3\n","{'id': 17, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5a2c2dcd-8276-4e40-a5f9-a4a946f55364', 'yolo_tag': ['coast'], 'yolo_detail': [0.616]}\n"," \n","idx =  4\n","{'id': 18, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b37f8797-0599-4566-9af2-967ae6ac22a9', 'yolo_tag': ['coast', 'person'], 'yolo_detail': [0.641, 1]}\n"," \n","idx =  5\n","{'id': 19, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a8e29e45-a740-4fc5-81f2-23f8ede8dd26', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.606]}\n"," \n","idx =  6\n","{'id': 20, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/718db959-ffbf-4e45-bd18-40ca476b8a19', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  7\n","{'id': 21, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/1ad530f9-e6fd-45d8-97f0-c4181df93661', 'yolo_tag': ['person'], 'yolo_detail': [1]}\n"," \n","idx =  8\n","{'id': 22, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/38076266-ea22-473d-89e0-22d0a189c815', 'yolo_tag': ['street'], 'yolo_detail': [0.482]}\n"," \n","idx =  9\n","{'id': 23, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/e16b3f01-0c9b-4451-b7e3-c32ede3af4dc', 'yolo_tag': ['Opencountry'], 'yolo_detail': [0.699]}\n"," \n","idx =  10\n","{'id': 24, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/44297d97-4ce8-4063-b8ab-ee39dee4397c', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.495]}\n"," \n","idx =  11\n","{'id': 25, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0c324854-1e9f-4881-afe4-0ac0cae9cf36', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  12\n","{'id': 26, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/791484ee-7894-4546-833f-7456f3dbfebc', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  13\n","{'id': 27, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/91dfaa53-536e-47c6-98f1-64d4180917d3', 'yolo_tag': ['person'], 'yolo_detail': [5]}\n"," \n","idx =  14\n","{'id': 28, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/a2a4db05-0a1e-4965-9809-60314c33bade', 'yolo_tag': ['street', 'person'], 'yolo_detail': [0.492, 2]}\n"," \n","idx =  15\n","{'id': 29, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3e1f8237-35b4-4182-8bf1-159f744dde03', 'yolo_tag': ['person'], 'yolo_detail': [1]}\n"," \n","idx =  16\n","{'id': 30, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3bd06b18-1dfd-4211-a2eb-18b8a647135f', 'yolo_tag': ['Opencountry'], 'yolo_detail': [0.639]}\n"," \n","idx =  17\n","{'id': 31, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2bc23ffa-43d7-40f3-88cd-4ca702fb02be', 'yolo_tag': ['street'], 'yolo_detail': [0.562]}\n"," \n","idx =  18\n","{'id': 32, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/7a316a4f-ca6e-4869-bd2f-ff0625be875d', 'yolo_tag': ['street', 'person'], 'yolo_detail': [0.75, 2]}\n"," \n","idx =  19\n","{'id': 33, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/d6a61ab6-8175-4d9e-87ce-6a2d89e3f53d', 'yolo_tag': ['forest'], 'yolo_detail': [0.86]}\n"," \n","idx =  20\n","{'id': 34, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/8a7c86e0-cf38-4f7b-a1b4-0a6154c498c9', 'yolo_tag': ['forest'], 'yolo_detail': [0.407]}\n"," \n","idx =  21\n","{'id': 35, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/32e669c2-79f3-40b9-ab6b-0133385a45a1', 'yolo_tag': ['tallbuilding'], 'yolo_detail': [0.482]}\n"," \n","idx =  22\n","{'id': 36, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/fda7c93c-8811-4796-82d8-7bd76dcfa68c', 'yolo_tag': ['tallbuilding'], 'yolo_detail': [0.481]}\n"," \n","idx =  23\n","{'id': 37, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/57b43dfa-742c-4363-9795-67ca5c01996d', 'yolo_tag': ['highway'], 'yolo_detail': [0.532]}\n"," \n","idx =  24\n","{'id': 38, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/75e1d1d8-a302-426c-9aa3-36061cd684b6', 'yolo_tag': ['mountain'], 'yolo_detail': [0.849]}\n"," \n","idx =  25\n","{'id': 39, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/5b47afef-1d15-4efd-94fa-31b09db51b73', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  26\n","{'id': 40, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/0b6a01eb-4e0b-4470-a9d6-b41320d6b896', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  27\n","{'id': 41, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/4e6ce2d1-a67b-4b20-a284-c56518801b00', 'yolo_tag': ['mountain'], 'yolo_detail': [0.481]}\n"," \n","idx =  28\n","{'id': 42, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/3b996ec1-3232-4c7f-9803-b1544ea1fbeb', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  29\n","{'id': 43, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/466563ef-b390-45ce-858f-62cc12f0ecd5', 'yolo_tag': ['coast'], 'yolo_detail': [0.887]}\n"," \n","idx =  30\n","{'id': 44, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/650706ac-3b3f-4e31-ac81-294930b87c49', 'yolo_tag': ['coast'], 'yolo_detail': [0.911]}\n"," \n","idx =  31\n","{'id': 45, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b8524464-79b5-4b8c-8e7b-061e41791add', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  32\n","{'id': 46, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c26abe17-c776-4c49-84e3-b97bf1b97fc6', 'yolo_tag': ['mountain'], 'yolo_detail': [0.606]}\n"," \n","idx =  33\n","{'id': 47, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/37e8edc7-b4bb-408b-8d2f-8f4c78a3efb0', 'yolo_tag': ['mountain'], 'yolo_detail': [0.428]}\n"," \n","idx =  34\n","{'id': 48, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/bd93c501-ab76-490d-9790-9c61d7a31dde', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.536]}\n"," \n","idx =  35\n","{'id': 49, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/2ec84e16-f984-40dc-9ead-785c4ecc9ea5', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  36\n","{'id': 50, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/c4b53cae-8583-4fd5-a9f6-838e8a245774', 'yolo_tag': [], 'yolo_detail': []}\n"," \n","idx =  37\n","{'id': 51, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/350b4b83-0fa2-437c-a40a-c4a0acb2584c', 'yolo_tag': ['mountain'], 'yolo_detail': [0.76]}\n"," \n","idx =  38\n","{'id': 52, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/b6282776-441b-4094-b738-81f53c0dea51', 'yolo_tag': ['highway', 'person'], 'yolo_detail': [0.45, 1]}\n"," \n","idx =  39\n","{'id': 53, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/efd80ed1-2f33-4a84-aad3-270d75fb3f04', 'yolo_tag': ['mountain'], 'yolo_detail': [0.71]}\n"," \n","idx =  40\n","{'id': 54, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/ce297c12-cc25-432d-b73f-fc8aa5f428ba', 'yolo_tag': ['mountain', 'inside_city', 'bowl'], 'yolo_detail': [0.472, 0.441, 4]}\n"," \n","idx =  41\n","{'id': 55, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/12a9c413-a323-4749-8ffc-a95b10489db0', 'yolo_tag': ['bowl'], 'yolo_detail': [5]}\n"," \n","idx =  42\n","{'id': 56, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/96278714-efbe-4624-828b-b9fdda612c21', 'yolo_tag': ['inside_city'], 'yolo_detail': [0.46]}\n"," \n","idx =  43\n","{'id': 57, 'url': 'https://capstone-aftertrip-test.s3.ap-northeast-2.amazonaws.com/21176cba-4fa3-4cd0-bece-61fea1e3cdd2', 'yolo_tag': [], 'yolo_detail': []}\n"," \n"]}]}]}